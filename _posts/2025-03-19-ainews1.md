---
layout: single
title: "AI News - OpenAI, 슈퍼인텔리전스 연구 본격 착수"
categories: AI News
tag: [OpenAI, AI, 슈퍼인텔리전스, AGI]
toc: true
author_profile: false
sidebar:
  nav: "docs"
---

## 발언 배경
- 샘 알트먼 OpenAI CEO는 최근 개인 블로그를 통해 "**AGI** (**Artificial General Intelligence**)를 어떻게 만들지 이미 안다"고 밝혔다.
- 이는 OpenAI가 전통적으로 정의해 온 AGI 수준을 넘어, "**슈퍼인텔리전스**" 연구에 본격적으로 착수할 것임을 시사한다. 
- 알트먼은 "슈퍼인텔리전스가 의외로 빨리 등장할 수 있으며, 그 파급효과는 상상 이상"이라고 언급하며, 이 기술이 가져올 변화에 대한 기대감을 드러냈다.

## AGI와 슈퍼인텔리전스
- OpenAI에 따르면, AGI는 "경제적으로 가치 있는 대부분의 작업을 **인간보다 잘 수행하는 고도의 자율 시스템**"으로 정의된다. 
- 슈퍼인텔리전스는 AGI보다 훨씬 더 강력하며, 과학 혁신의 속도를 대폭 높여 풍요로운 미래를 이끌 것으로 기대되고 있다. 
- 이러한 연구는 인류의 발전에 긍정적인 기여를 할 가능성이 크다.

## MS와의 협정
- OpenAI는 **Microsoft**와의 투자 계약을 통해 AI가 연간 **1000억 달러 이상**의 이익을 창출할 경우, Microsoft는 **OpenAI 기술에 대한 접근을 제한**하는 조건을 설정했다. 
- 알트먼은 "올해부터 **AI 에이전트**가 실제 노동력을 바꿀 수 있으며, 기업의 **생산성 향상**에 기여할 것"이라고 전망하고 있다. 
- 이러한 협정은 OpenAI가 **상업적 성공**을 거두는 동시에 **기술적 혁신**을 이루겠다는 의지를 반영한다.

## 기술 한계 및 일정
- AI 모델의 **환각(hallucination), 오류, 비싼 운용비** 등은 여전히 중대한 과제이다.
- 알트먼은 이러한 문제들이 빠르게 해결될 가능성을 언급했지만, 과거의 경험을 바탕으로 **예측이 부정확**할 수 있음을 인정했다. 
- 이는 AI 기술 발전의 불확실성을 보여주는 중요한 요소이다.

## 안전 및 조직 이슈
- OpenAI는 과거에 "슈퍼인텔리전스를 통제할 기술이나 방법이 없다"고 인정한 바 있다.
- 최근 AI 안전 전담팀의 일부 해체와 연구자들의 이탈 등 **내부적 갈등**이 발생하고 있으며, **상업화 우선 정책에 대한 비판**도 제기되고 있다. 
- 이러한 상황은 OpenAI가 기술 개발과 안전성 간의 균형을 찾는 데 어려움을 겪고 있음을 나타낸다.

## 의의 및 전망
- 슈퍼인텔리전스가 구현될 경우, 과학과 경제 전반의 혁신 속도가 상승할 것으로 기대되지만, 동시에 **윤리와 책임**에 대한 우려도 증대할 것이다. 
- AI가 점차 '**인간이 통제하기 어려운**' 지점에 가까워짐에 따라 **안전성, 규제, 국제적 협력**이 핵심 이슈로 부상하고 있다. 
- OpenAI의 행보는 글로벌 AI 시장과 사회 전반에 큰 영향을 미칠 것으로 전망되며, 이러한 변화에 대비하기 위한 논의가 더욱 활발해져야 할 것이다.